\section{Evaluation methodology}

acbd

\begin{table*}
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|}
\hline
\hline

\hline
Project & Class & LOC & Methods & Tests & Statements \\
\hline
\hline
{\tt CruiseControl} & AntBuilder & 499 & 33 & 22 & xx\\
\hline
{\tt CruiseControl} & Schedule & 383 & 30 & 18 & xx\\
\hline
{\tt CruiseControl} & Project & xx & xx & xx & xx\\
\hline
{\tt Ant} & Available & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Ant} & Copy & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Ant} & FixCRLF & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Validator} & UrlValidator & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Validator} & RegexValidator & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Validator} & DomainValdiator & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Jexl3} & Engine & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Jexl3} & JexlArithmetic & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Jexl3} & JexlEvalContext & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Cli} & DafaultParser & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Cli} & GnuParser & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Cli} & PosixParser & 6.45 & 25 & 4.54 & 23\\
\hline
{\tt Jena} & LocationMapper & 6.45 & 25 & 4.54 & 23\\\\
\hline
{\tt Jena} & OntlClassImpl & 6.45 & 25 & 4.54 & 23\\\\
\hline
{\tt Jena} & OntlClassImpl & 6.45 & 25 & 4.54 & 23\\\\
\hline
{\tt Text} & ExtendedMessageFormat & 6.45 & 25 & 4.54 & 23\\\\
\hline
{\tt Text} & ExtendedMessageFormat & 6.45 & 25 & 4.54 & 23\\\\
\hline
{\tt Text} & ExtendedMessageFormat & 6.45 & 25 & 4.54 & 23\\\\

\hline
\hline
\end{tabular}
\end{center}
\caption{Reduction size for subject classes}
\label{tab:avgimproved}
\end{table*}



In order to measure the applicability and accuracy of \mytool\, as well as evaluate the reductions produced by our methodology, we chose 21 java classes from 7 projects of varying size, purpose and complexity. From each of 7 open source java project, we chose 3 classes randomly. These classes have average LOC (non empty, non comment) 398 lines, with maximum being 1302 and minimum being 64. These classes contains on average 24 methods, with max and min being 64 and 1. Information related to all 21 classes are shown in Table. For experiment purpose, we choose class as a component. 

In real world scenario, developers will be well aware of their system and tests and will label the tests accurately based on their importance. They will choose the tests pertaining to certain functionality if they want to reduce component associated with that functionality.  For experimental purpose, to demonstrate use of our tool, we first selected test cases based on its CC and CR values as described in section subsection, CC and CR values should be 1. It prevents all tests from running while a class is being reduced and converges faster. The process gave us certain number of tests to consider for each of the class chosen from reduction. The process gave us close to 30 tests per class on average, while maximum tests selected was 58 and minimum was 7. for further discussion, we call these tests \emph{selected tests}. 

We then did test case labeling using the following process. We allowed 3 labels 0,1 and 2, 0 being most important test cases that determines minimum allowable system. System generated by label 1 and 2 are the reduced systems generated based on adaptation, System generated by removing tests with label 2 is the system closest to original system. It is important to note that when we remove tests at label x, we also remove any tests at label x+1, as label x test cases are more important then label x test cases as per our design. We iterate through the \emph{selected test cases} and label each test case with 80\% probability of being label as 0, 10\% probability of being label as 1 and 10\% probability of being label as 2. Default label of test is 0, so if a lable is not present, it is considered 0. The process keeps 80\% system as minimum allowable system while still giving us 2 reduced versions. If during the labeling process, if all the 3 labels don't appear, we throw that data point out and re generate the data. In real world, developer may choose not to label any test case with lable 1 or lable 2 test cases. For our experiment purpose, we want to have all the labels and 2 extra reduced versions to be generated for each class and hence the bias. 

Consider a component C with test suite T. Initially no tests with any test labels are removed so we call this test suite $T_\infty$ and corresponding component $C_\infty$. We call a test suite $T_n$ if it is generated by removing all the tests whose labels are n and above. We call reduced version generated by test suite $T_{n}$ as component $C_{n}$. The way labeling and corresponding test removal is defined, it is important to note that $T_{\infty}$ $\supseteq$  .... $T_{n+1}$ $\supseteq$ $T_{n}$ $\supseteq$ $T_{n-1}$ ......  $\supseteq$ $T_{1}$ and $C_{\infty}$ ...... $\supseteq$  $C_{n+1}$ $\supseteq$ $C_{n}$ $\supseteq$ $C_{n-1}$ ..... $\supseteq$ $C_{1}$. $T_{0}$ and $P_{0}$ are not possible because they violate minimal allowable functionality as defined by label 0. 
	
In order to prevent bias in test case labeling (an important test labeled as 2, may remove too much functionality), we repeat the process 10 times, allowing random labeling each time. For each of such labeling, we reduce the class, giving us 10 versions for label 1 and 10 versions for label 2. We repeat the process for each of the 21 classes giving us in total 420 reduced versions, 210 for label 1 and 210 for label 2.    

We also want to evaluate and compare reduced versions of the class. In order to evaluate reductions, we measure (1) number of statements removed (2) highest level from leaf level the statement is removed in AST of class. If reduction is higher, large number of statements are removed, and reduced version differ significantly from its original version. If average highest level from leaf level is small, mostly simple statements are removed while highest level from leaf level is big, blocks are removed. 

In order to measure accuracy of the tool, we randomly chose 20 reductions out of 420 reductions generated. For each of such reduction; using test case labeling and \emph{selected test cases} we manually generated 1-minimal class. As we are not following any systematic algorithm like hdd to do it automatically, we produced global minimal class. We measure accuracy in terms of statement reduction.  For each reduction produced by \mytool\ and hand, we define following terms. 

\begin{itemize}
\item \emph{TruePositive} : a statement is true positive if it is removed in both hand reduction and reduction by \mytool\
\item \emph{FalsePositive} : a statement is reduced by \mytool\ while it is not reduced in hand reduction, \mytool\ incorrectly removed a statement.
\item \emph{FalseNegative} : a statement is reduced in hand reduction but it is not reduced by \mytool\, \mytool\ missed the reduction.
\end{itemize}
   
 


   

 


